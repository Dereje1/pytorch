{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3/aT3J5GgijbPgHoeyo2/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dereje1/pytorch/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNZLGUnXcDAB",
        "outputId": "56a67612-e8e0-4c38-acbe-b30d9fb16ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction to Tensors\n",
        "\n",
        "Creating tensors\n",
        "\n",
        "Pytorch tensors are created with torch.tensor() -> reference -> https://pytorch.org/docs/stable/tensors.html"
      ],
      "metadata": {
        "id": "hXPFuU-Lhprp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Scalars, vectors, matrices and tensors"
      ],
      "metadata": {
        "id": "S4i1pwaDzdKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scalar\n",
        "scalar = torch.tensor(7)\n",
        "print(f\"scalar = { scalar } \\nndim -> {scalar.ndim} shape -> {scalar.shape} item -> {scalar.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj8tS3kFh5AN",
        "outputId": "bcde37d8-9706-4cb8-82cf-f1c5f3ba46c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scalar = 7 \n",
            "ndim -> 0 shape -> torch.Size([]) item -> 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Vector\n",
        "vector = torch.tensor([7,7])\n",
        "print(f\"Vector = { vector } \\nndim -> {vector.ndim} shape -> {vector.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl09UcSDkCzU",
        "outputId": "1b99514e-fd16-4a28-db30-b0cb8eab86c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector = tensor([7, 7]) \n",
            "ndim -> 1 shape -> torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MATRIX\n",
        "MATRIX = torch.tensor([[7,8], [9,10]])\n",
        "print(f\"Matrix = { MATRIX } \\nndim -> {MATRIX.ndim} shape -> {MATRIX.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8miIdLwkXMi",
        "outputId": "cf0357e8-12e9-4b40-809c-302bf8a088a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix = tensor([[ 7,  8],\n",
            "        [ 9, 10]]) \n",
            "ndim -> 2 shape -> torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The torch.size indicates the shape of a tensor, and describes the number of elements along each dimension. In the case of a tensor t with shape (2, 4, 3) as below, it means that the tensor has 3 dimensions, with the first dimension having a size of 2, the second dimension having a size of 4, and the third dimension having a size of 3. In other words, the tensor has 2 rows, each row has 4 columns, and each column has 3 elements. The total number of elements in the tensor is the product of the sizes of all dimensions, which in this case is 2 * 4 * 3 = 24\n",
        "\n",
        "So maybe one way to think of 3 dimensions is as a cube with height (2), width (4) and depth (3)... but any more additional dims will be hard to mentally picture"
      ],
      "metadata": {
        "id": "Q-bAHnXCCNDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TENSOR\n",
        "TENSOR = torch.tensor([\n",
        "    [\n",
        "        [1,2,3],\n",
        "        [4,5,6],\n",
        "        [7,8,9],\n",
        "        [10,11,12]\n",
        "    ],\n",
        "    [\n",
        "        [11,21,31],\n",
        "        [41,51,61],\n",
        "        [71,81,91],\n",
        "        [101,111,121]\n",
        "    ]\n",
        "    ])\n",
        "print(f\"Tensor = { TENSOR } \\nndim -> {TENSOR.ndim} shape -> {TENSOR.shape} totalElements -> {TENSOR.numel()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9FADd-wl7vT",
        "outputId": "3a64a90e-7a46-42f2-c384-9de0c43eafc0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor = tensor([[[  1,   2,   3],\n",
            "         [  4,   5,   6],\n",
            "         [  7,   8,   9],\n",
            "         [ 10,  11,  12]],\n",
            "\n",
            "        [[ 11,  21,  31],\n",
            "         [ 41,  51,  61],\n",
            "         [ 71,  81,  91],\n",
            "         [101, 111, 121]]]) \n",
            "ndim -> 3 shape -> torch.Size([2, 4, 3]) totalElements -> 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Tensors\n",
        "\n",
        "Why Random tensors ?\n",
        "\n",
        "Random tensors are important since the way many nueral networks learn is by starting with a matix of random numbers and then iterate over those numbers to fit the data\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`"
      ],
      "metadata": {
        "id": "vHB0Rel0p3lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create random tensors with pytorch of size (3,4)\n",
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI4Z7rRZqPVr",
        "outputId": "0eb528d4-b109-4482-9749-2dccee0a3bf5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1361, 0.8305, 0.5345, 0.6264],\n",
              "        [0.7558, 0.5776, 0.9246, 0.3991],\n",
              "        [0.1151, 0.1537, 0.0799, 0.2784]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a random tensor with a similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224,224,3)) #Height, width, color channel (R,G,B)\n",
        "random_image_size_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-uv6vZArhk9",
        "outputId": "07a3ae35-50a4-4e6e-e354-c0b5244ffce2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3380, 0.4000, 0.6832],\n",
              "         [0.1615, 0.0912, 0.7950],\n",
              "         [0.8454, 0.6488, 0.1745],\n",
              "         ...,\n",
              "         [0.8825, 0.6653, 0.7626],\n",
              "         [0.0619, 0.3041, 0.3764],\n",
              "         [0.5176, 0.7306, 0.4461]],\n",
              "\n",
              "        [[0.4949, 0.7145, 0.8369],\n",
              "         [0.1128, 0.7711, 0.5600],\n",
              "         [0.6321, 0.7264, 0.4214],\n",
              "         ...,\n",
              "         [0.7661, 0.3918, 0.2580],\n",
              "         [0.6514, 0.4240, 0.7346],\n",
              "         [0.5534, 0.8329, 0.7834]],\n",
              "\n",
              "        [[0.8049, 0.1664, 0.4045],\n",
              "         [0.0169, 0.6773, 0.8870],\n",
              "         [0.0923, 0.4141, 0.4984],\n",
              "         ...,\n",
              "         [0.8306, 0.7839, 0.0767],\n",
              "         [0.9087, 0.4500, 0.0129],\n",
              "         [0.1748, 0.1398, 0.2619]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.0256, 0.9906, 0.9303],\n",
              "         [0.2985, 0.9062, 0.4345],\n",
              "         [0.9142, 0.9572, 0.5837],\n",
              "         ...,\n",
              "         [0.4762, 0.0896, 0.1297],\n",
              "         [0.2442, 0.6554, 0.2984],\n",
              "         [0.7830, 0.7635, 0.1801]],\n",
              "\n",
              "        [[0.2127, 0.1829, 0.9748],\n",
              "         [0.1597, 0.0090, 0.6963],\n",
              "         [0.8730, 0.6987, 0.2271],\n",
              "         ...,\n",
              "         [0.2796, 0.9898, 0.3716],\n",
              "         [0.7664, 0.9122, 0.5409],\n",
              "         [0.3953, 0.5140, 0.1316]],\n",
              "\n",
              "        [[0.8861, 0.3325, 0.5204],\n",
              "         [0.4343, 0.7585, 0.7311],\n",
              "         [0.0100, 0.6542, 0.0239],\n",
              "         ...,\n",
              "         [0.6927, 0.2852, 0.3480],\n",
              "         [0.2087, 0.5754, 0.1531],\n",
              "         [0.5372, 0.1404, 0.4150]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbmsUzmntC-I",
        "outputId": "66fd88a1-963e-44cb-aa4e-3e82564395fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros and ones"
      ],
      "metadata": {
        "id": "nPf-xer4tNvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a tensor of all zeroes and ones\n",
        "zeroes = torch.zeros(3,4)\n",
        "ones=torch.ones(3,4)\n",
        "zeroes\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6cMQa4Dulj3",
        "outputId": "ea9b9717-3df1-4dbf-8262-9a77812d0c40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeroes.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOQ-HxDtuxHx",
        "outputId": "77c0e488-aadc-433b-c6ea-0a5c0baf5cc3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating a range of tensors and tensors-like"
      ],
      "metadata": {
        "id": "amaFV8tZwgBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_to_ten = torch.arange(1, 11, 1) # third arg is step\n",
        "one_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdPuO4Ppu3q5",
        "outputId": "5f3894b7-53ca-4fee-b5d0-c0753ed9526b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating tensors like\n",
        "ten_zeroes = torch.zeros_like(one_to_ten)\n",
        "ten_zeroes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2ntrdCFv7Y2",
        "outputId": "f4593452-6a40-41c1-adc4-4b1698b46435"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Datatypes"
      ],
      "metadata": {
        "id": "TQ1lZX6ZxCgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Float 32 Tensor\n",
        "float_32_tensor = torch.tensor([1.0,2.0,3.0],\n",
        "                               dtype=None, # what datatype the tensor is default is float32 -> adjust precision with memory/perf tradeoff\n",
        "                               device=None, # default is 'cpu', the device the tensor is on\n",
        "                               requires_grad=False) # track 'gradients' (or not)\n",
        "float_16_tensor = torch.tensor([1.0,2.0,3.0],\n",
        "                               dtype=torch.float16)\n",
        "\n",
        "float_32_tensor.dtype\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLfmaHe-0lpN",
        "outputId": "157e25ba-51fc-4c77-9ca0-02d32dc48a80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor * float_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urx83HQH3Mja",
        "outputId": "90d04178-7297-45b8-f717-77e9cc0bbd22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 4., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Information from tensors\n",
        "\n",
        "\n",
        "\n",
        "1.   Tensors not the right data type - get data type `tensor.dtype`\n",
        "2.   Tensors not the right shape - get shape `tensor.shape`\n",
        "3.   Tensors not the right device - get shape `tensor.device`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gkHAOGNq-B_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor\n",
        "some_Tensor = torch.rand(3,4)\n",
        "some_Tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sivnwEau_5ZG",
        "outputId": "fb1d6bbd-6167-4b5d-b2d1-1131be2b0fbf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1112, 0.0651, 0.3835, 0.2691],\n",
              "        [0.0813, 0.6969, 0.7429, 0.3186],\n",
              "        [0.1004, 0.2341, 0.9461, 0.7249]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out details of a tensor\n",
        "some_Tensor = some_Tensor.to(torch.float64)\n",
        "print(some_Tensor)\n",
        "print(f\"Data type of tensor: {some_Tensor.dtype}\")\n",
        "print(f\"Shape of tensor: {some_Tensor.shape}\")\n",
        "print(f\"Device of tensor: {some_Tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IvSWiefAQjC",
        "outputId": "290f4fb2-3e52-46e5-dec6-a17416889733"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1112, 0.0651, 0.3835, 0.2691],\n",
            "        [0.0813, 0.6969, 0.7429, 0.3186],\n",
            "        [0.1004, 0.2341, 0.9461, 0.7249]], dtype=torch.float64)\n",
            "Data type of tensor: torch.float64\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Device of tensor: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulating tensors (tensor operations)\n",
        "Addition\n",
        "\n",
        "* Addition\n",
        "* Substraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication"
      ],
      "metadata": {
        "id": "1PTf9UtWFGU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Addition\n",
        "tensor = torch.tensor([1,2,3])\n",
        "print(tensor + 15)\n",
        "# Subtract\n",
        "print(tensor -10)\n",
        "# Multiply\n",
        "print(tensor * 10)\n",
        "# divide\n",
        "print(tensor/2)\n",
        "# matrix multiply (dot product)\n",
        "matrix_to_multiply = torch.tensor([[1],[2],[3]])\n",
        "torch.matmul(tensor, matrix_to_multiply) # (1*1 + 2*2 + 3*3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqGwmXsMFw9D",
        "outputId": "8803a945-9660-4b76-929b-6af67ee5df5d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([16, 17, 18])\n",
            "tensor([-9, -8, -7])\n",
            "tensor([10, 20, 30])\n",
            "tensor([0.5000, 1.0000, 1.5000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([14])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## example of dot product from here https://www.mathsisfun.com/algebra/matrix-multiplying.html but using pytorch\n",
        "a = torch.tensor([[1,2,3],[4,5,6]])\n",
        "b = torch.tensor([[7,8],[9,10],[11,12]])\n",
        "torch.matmul(a,b)\n",
        "## note that matmul is way faster than using a traditional for loop\n",
        "## as in any dot product calculation number of rows of a == number columns of b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLp08UG1JyMM",
        "outputId": "c69ce574-9cc1-4fcd-e88a-2eee151b99eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58,  64],\n",
              "        [139, 154]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transposing tensors"
      ],
      "metadata": {
        "id": "XrxCo8B9P2no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Transpose\n",
        "tensor = torch.tensor([[1,2,3]])\n",
        "print(f\"Original Tensor -> {tensor}, size -> {tensor.shape}\")\n",
        "transposed_Tensor = tensor.T\n",
        "print(f\"Transposed Tensor -> {transposed_Tensor}, size -> {transposed_Tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP4nOO-_J6N8",
        "outputId": "581c4fd1-27e0-4e15-d317-fdcfece44fde"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor -> tensor([[1, 2, 3]]), size -> torch.Size([1, 3])\n",
            "Transposed Tensor -> tensor([[1],\n",
            "        [2],\n",
            "        [3]]), size -> torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregations (min, max, sum ...)"
      ],
      "metadata": {
        "id": "NFaFzce9W7Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "print(x)\n",
        "x_min = torch.min(x) # or you can just use x.min() ...ditto for the rest\n",
        "x_min_position = torch.argmin(x)\n",
        "x_max = torch.max(x)\n",
        "x_max_position = torch.argmax(x)\n",
        "x_mean = torch.mean(x.to(torch.float64)) # note here that mean can not work on integers\n",
        "x_total = torch.sum(x)\n",
        "print(f\"min -> {x_min}, position -> {x_min_position}, \\nmax -> {x_max}, position -> {x_max_position}, \\nave -> {x_mean}, \\ntotal -> {x_total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1VTZVR8XBpQ",
        "outputId": "d3c7743d-dd4d-4c07-8b23-e2499d5ae819"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "min -> 0, position -> 0, \n",
            "max -> 90, position -> 9, \n",
            "ave -> 45.0, \n",
            "total -> 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "\n",
        "\n",
        "*   Reshaping - given an input tensor, change to defined shape\n",
        "*   View - Returns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
        "* Stacking - Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
        "* Squeeze - Squeezes input to remove all the dimenions with value 1.\n",
        "* UnSqueeze - Returns input with a dimension value of 1 added at dim.\n",
        "* Permute - Returns a view of the original input with its dimensions permuted (rearranged) to dims\n",
        "\n"
      ],
      "metadata": {
        "id": "Dqx7eFzTKYlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reshaping - add an extra dimension\n",
        "x = torch.arange(1,10)\n",
        "print(x, x.shape)\n",
        "## note that new dimensions must be congruent with the shape we want to change or will error, TODO: play around with this\n",
        "x_reshaped = x.reshape(9,1)\n",
        "print(x_reshaped, x_reshaped.shape)\n",
        "x_reshaped = x.reshape(1,9)\n",
        "print(x_reshaped, x_reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqdPUATMOKuU",
        "outputId": "55751d22-b508-4057-e72b-00bd0c9f25e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) torch.Size([9])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6],\n",
            "        [7],\n",
            "        [8],\n",
            "        [9]]) torch.Size([9, 1])\n",
            "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]) torch.Size([1, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Change the view\n",
        "x = torch.arange(1,10)\n",
        "print(x, x.shape)\n",
        "# same as reshape, however this shares the same memory as the original tensor, so if you change z then x will change as well\n",
        "z = x.view(1, 9)\n",
        "print(z, z.shape)\n",
        "## example of the mutation carrying on to the original tensor\n",
        "z[0][3] = 19\n",
        "print(z, z.shape)\n",
        "print(x, x.shape) # <- note here that x changed too!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6bRIMdjRuBT",
        "outputId": "a65cdd50-39be-4f95-e7c3-7433fdefc968"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) torch.Size([9])\n",
            "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]) torch.Size([1, 9])\n",
            "tensor([[ 1,  2,  3, 19,  5,  6,  7,  8,  9]]) torch.Size([1, 9])\n",
            "tensor([ 1,  2,  3, 19,  5,  6,  7,  8,  9]) torch.Size([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Stack tensors ontop of each other\n",
        "x = torch.arange(1,10)\n",
        "print(x, x.shape)\n",
        "x_stacked = torch.stack([x, x, x], dim=0) # default\n",
        "print(f\"stacked default \\n{x_stacked}, size={x_stacked.shape}\")\n",
        "x_stacked = torch.stack([x, x, x], dim=1)\n",
        "print(f\"stacked dim = 1 \\n{x_stacked}, size={x_stacked.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2ht9716SW_T",
        "outputId": "9fd6c1a8-6ddc-4e63-c780-2c9520a045b0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) torch.Size([9])\n",
            "stacked default \n",
            "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "        [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "        [1, 2, 3, 4, 5, 6, 7, 8, 9]]), size=torch.Size([3, 9])\n",
            "stacked dim = 1 \n",
            "tensor([[1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [4, 4, 4],\n",
            "        [5, 5, 5],\n",
            "        [6, 6, 6],\n",
            "        [7, 7, 7],\n",
            "        [8, 8, 8],\n",
            "        [9, 9, 9]]), size=torch.Size([9, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## squeeze - removes all single dimensions from a target tensor\n",
        "print(f\"Original -> {x_reshaped} size -> {x_reshaped.shape}\")\n",
        "squeezed = x_reshaped.squeeze()\n",
        "print(f\"Squeezed -> {squeezed} size -> {squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbJrwuOm58Rb",
        "outputId": "07fbb6c6-e067-49b7-9f10-3b819d146cd4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original -> tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]) size -> torch.Size([1, 9])\n",
            "Squeezed -> tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) size -> torch.Size([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## unsqueeze - adds a single dimensions to a target tensor\n",
        "print(f\"Original -> {squeezed} size -> {squeezed.shape}\")\n",
        "unsqueezed = squeezed.unsqueeze(dim=0)\n",
        "print(f\"Unsqueezed -> {unsqueezed} size -> {unsqueezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GurWcx9j715m",
        "outputId": "364fb022-9db8-4ca1-f97e-0b2c0707a8cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original -> tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) size -> torch.Size([9])\n",
            "Unsqueezed -> tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]) size -> torch.Size([1, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## permute - rearranges the dimensions of a target tensor in a specified order\n",
        "x_original = torch.rand(size=(224,224,3)) #Height, width, color channel (R,G,B)\n",
        "print(f\"original shape -> {x_original.shape}\")\n",
        "\n",
        "## permute the original tensor to reaarange the axis (or dim)\n",
        "## say you want to permute to color channels, Height, width\n",
        "x_permuted = x_original.permute(2,0,1) #where 2 was the orginal dim for the color channel and so forth\n",
        "print(f\"Permuted shape -> {x_permuted.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgAJCeLN9PoV",
        "outputId": "0b8a1808-5734-4f04-8166-89eec05df70e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape -> torch.Size([224, 224, 3])\n",
            "Permuted shape -> torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing (selecting data in tensors)\n",
        "\n",
        "Indexing in pyTorch is similar to Numpy"
      ],
      "metadata": {
        "id": "khcaunt-_rth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1,10).reshape(1,3,3)\n",
        "print(f\"x -> {x}, \\nshape -> {x.shape}, \\ntotal dimensions -> {x.ndim}\")\n",
        "## Indexing the tensor, on the first dimension\n",
        "print(f\"\\nFirst dimension -> {x[0]}\")\n",
        "print(f\"\\nFirst dimension, First row -> {x[0][0]}\") ## can also be written as x[0,0]\n",
        "print(f\"\\nFirst dimension, First row, third element -> {x[0][0][0]}\")\n",
        "print(f\"\\nFirst dimension, third row, third element -> {x[0][2][2]}\")\n",
        "\n",
        "## You can also use \":\" to select all of a target dimension\n",
        "print(f\"\\nFirst dimension, second row -> {x[:, 1]}\")\n",
        "\n",
        "## or you can select, all the dimensions upto a certain index of the last\n",
        "print(f\"\\nFirst dimension, all rows, all second elements -> {x[:, : ,1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeIcOF1-4Z-D",
        "outputId": "42ee432a-e99e-465a-933e-1c7bbb45b54f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x -> tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]]), \n",
            "shape -> torch.Size([1, 3, 3]), \n",
            "total dimensions -> 3\n",
            "\n",
            "First dimension -> tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "\n",
            "First dimension, First row -> tensor([1, 2, 3])\n",
            "\n",
            "First dimension, First row, third element -> 1\n",
            "\n",
            "First dimension, third row, third element -> 9\n",
            "\n",
            "First dimension, second row -> tensor([[4, 5, 6]])\n",
            "\n",
            "First dimension, all rows, all second elements -> tensor([[2, 5, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch tensors and NumPy\n",
        "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "\n",
        "`torch.from_numpy(ndarray)` - NumPy array -> PyTorch tensor.\n",
        "\n",
        "`torch.Tensor.numpy()` - PyTorch tensor -> NumPy array."
      ],
      "metadata": {
        "id": "bgZohzJx__XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Numpy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor ## note that its is using numpy's default datatype on the tensor and not torch's"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfer2oqnBQAd",
        "outputId": "49c92f6c-14eb-4c60-ee5e-c51f408539b8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tensor to numpy array\n",
        "tensor = torch.rand(3)\n",
        "numPyArr = tensor.numpy()\n",
        "print(f\"tensor -> {tensor} \\nNumpy array -> {numPyArr}\") ## note the datatype change"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgC1eZ43DYIY",
        "outputId": "b1ffabe9-0b49-4e13-9a6d-47b44acae8eb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor -> tensor([0.3188, 0.7726, 0.6359]) \n",
            "Numpy array -> [0.31881148 0.7726105  0.635903  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibiity (trying to take the random out of random )\n",
        "For more detail see here: https://pytorch.org/docs/stable/notes/randomness.html#reproducibility\n",
        "\n",
        "In short how a neural network learns:\n",
        "\n",
        "`start with random numbers -> tensor operations -> update random numbers to make a better fit of the data -> Rinse repeat...`\n",
        "\n",
        "To reduce the randomness in nueral networks and pyTorch, the concept of **Random seed** comes in\n",
        "\n",
        "An explanation from bing chat on what a random seed is:\n",
        "\n",
        "> A random seed is a **starting point** in generating random numbers. It specifies the start point when a computer generates a random number sequence ². This can be any number, but it usually comes from seconds on a computer system’s clock ². A random seed is used to initialize a pseudorandom number generator ¹. The sequence of numbers generated by the pseudorandom number generator is completely determined by the seed, so if it is reinitialized with the same seed, it will produce the same sequence of numbers ¹.\n",
        "\n",
        "*Source: Conversation with Bing, 7/19/2023\n",
        "(1) Random Seed: Definition - Statistics How To. https://www.statisticshowto.com/random-seed-definition/.\n",
        "(2) Random seed - Wikipedia. https://en.wikipedia.org/wiki/Random_seed.\n",
        "(3) The story behind ‘random.seed(42)’ in machine learning. https://medium.com/geekculture/the-story-behind-random-seed-42-in-machine-learning-b838c4ac290a.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eaiB9nPiNfZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Examples, say you have two random generated tensors, naturally it would be very unlikely for them to be equal..\n",
        "import torch\n",
        "rand_tensor_x = torch.rand(2,3)\n",
        "rand_tensor_y = torch.rand(2,3)\n",
        "print(rand_tensor_x)\n",
        "print(rand_tensor_y)\n",
        "print(f\"Are the tensors equal ? -> {rand_tensor_x == rand_tensor_y}\")\n",
        "\n",
        "## but now set a Random seed\n",
        "RAND_SEED = 42 # can be anything really\n",
        "torch.manual_seed(RAND_SEED)\n",
        "rand_tensor_u = torch.rand(2,3)\n",
        "torch.manual_seed(RAND_SEED) # note that you have to set the seed every time BEFORE you generate the numbers!\n",
        "rand_tensor_v = torch.rand(2,3)\n",
        "print(rand_tensor_u)\n",
        "print(rand_tensor_v)\n",
        "print(f\"Are the tensors equal now ? -> {rand_tensor_u == rand_tensor_v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgqX4t_-NwSr",
        "outputId": "55fe4328-6699-43b5-8584-bc81c82167b8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0873, 0.0595, 0.6177],\n",
            "        [0.0947, 0.3213, 0.4410]])\n",
            "tensor([[0.0567, 0.8188, 0.3860],\n",
            "        [0.7521, 0.3172, 0.8480]])\n",
            "Are the tensors equal ? -> tensor([[False, False, False],\n",
            "        [False, False, False]])\n",
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009]])\n",
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009]])\n",
            "Are the tensors equal now ? -> tensor([[True, True, True],\n",
            "        [True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Tensors and pytorch objects on the GPUs and making faster computations\n",
        "\n",
        "GPUs = Faster computation of numbers, thanks to CUDA + NVIDIA hardware + pyTorch\n",
        "\n",
        "*Taken from the notes section of tutorial below*\n",
        "### 1. Getting a GPU\n",
        "\n",
        "You may already know what's going on when I say GPU. But if not, there are a few ways to get access to one.\n",
        "\n",
        "| **Method** | **Difficulty to setup** | **Pros** | **Cons** | **How to setup** |\n",
        "| ----- | ----- | ----- | ----- | ----- |\n",
        "| Google Colab | Easy | Free to use, almost zero setup required, can share work with others as easy as a link | Doesn't save your data outputs, limited compute, subject to timeouts | [Follow the Google Colab Guide](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
        "| Use your own | Medium | Run everything locally on your own machine | GPUs aren't free, require upfront cost | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/locally/) |\n",
        "| Cloud computing (AWS, GCP, Azure) | Medium-Hard | Small upfront cost, access to almost infinite compute | Can get expensive if running continually, takes some time to setup right | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/cloud-partners/) |\n",
        "\n",
        "There are more options for using GPUs but the above three will suffice for now.\n",
        "Personally, I use a combination of Google Colab and my own personal computer for small scale experiments (and creating this course) and go to cloud resources when I need more compute power.\n",
        "> **Resource:** If you're looking to purchase a GPU of your own but not sure what to get, [Tim Dettmers has an excellent guide](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
        "\n",
        "To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means \"run this on the command line\".\n",
        "\n"
      ],
      "metadata": {
        "id": "k71L7ca4Us1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## already covered this, but to see if you are running on gpu change the run type above, if you are not you will simply get a command not found...\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zonKZRX-Xejz",
        "outputId": "0a8d621a-e5ac-440a-d7cf-f1c5572a1c71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul 19 09:09:05 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Getting PyTorch to run on the GPU"
      ],
      "metadata": {
        "id": "ePtlSqgUe9CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## You can also check for GPU access with pyTorch\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afiAof-EauNx",
        "outputId": "281e82ed-898d-4eb6-876a-2a49f3448ff3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup device agnostic code\n",
        "# see here if you writing scripts and not using google colab https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device ## will see where can use device as a variable later"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ehMj3AvlbAg2",
        "outputId": "cfca5cdd-2c63-451a-ac35-7a53bbf1bac1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the # of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEdwNlPHcFvV",
        "outputId": "9138c63a-8b92-45de-f1a7-0f10deb461d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Putting tensors (and models) on the GPU and back on the CPU"
      ],
      "metadata": {
        "id": "ge-ud3oQfPZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## by default tensors are created on a cpu\n",
        "tensor = torch.tensor([1,2,3])\n",
        "print(f\"device of tensor --> {tensor.device}\")\n",
        "## but you can move it to a gpu by using the device variable we created above and reassigning to new tensor\n",
        "tensor_on_gpu = tensor.to(device = device)\n",
        "print(f\"device of tensor --> {tensor_on_gpu.device}\")\n",
        "## but sometimes you want to flip back onto cpu, for ex if you want to do a numpy calculation\n",
        "\n",
        "tensor_on_gpu.cpu().numpy() ## note here that hadn't you used the cpu method before invoking numpy it would error out..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5LjFkp6fRky",
        "outputId": "e7d725be-4945-4800-e216-dff9ab4a1894"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device of tensor --> cpu\n",
            "device of tensor --> cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}